import flask
from transformers import TFBertForSequenceClassification, BertTokenizer
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import tensorflow as tf
import numpy as np
import requests
import json
import os
import google.generativeai as genai

app = Flask(__name__)
CORS(app)  

# Load the BERT model and tokenizer
def load_model_and_tokenizer():
    try:
        model_path = 'model'
        tokenizer_path = 'tokenizer'
        model = TFBertForSequenceClassification.from_pretrained(model_path)
        tokenizer = BertTokenizer.from_pretrained(tokenizer_path)
        return model, tokenizer
    except Exception as e:
        print(f"Error loading model or tokenizer: {e}")
        return None, None

MODEL, TOKENIZER = load_model_and_tokenizer()

def get_geolocation(ip_address):
    try:
        response = requests.get(f'https://ipapi.co/{ip_address}/json/')
        if response.status_code == 200:
            return response.json()
        return None
    except Exception as e:
        print(f"Geolocation lookup error: {e}")
        return None

def fetch_local_support_centers(latitude, longitude):
    support_centers = [
        {
            "name": "Local Crisis Center",
            "phone": "1-800-HELP",
            "address": "123 Support St",
            "distance": "2 miles"
        }
    ]
    return support_centers

def get_gemini_response(prompt):
    """
    Fetches a response from the Gemini API using the provided prompt.

    Args:
      prompt: The input prompt for the Gemini model.

    Returns:
      The text response generated by the Gemini model, or None if error occurs.
    """

    # Get API key from environment variable
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise ValueError("GEMINI_API_KEY environment variable not set.")

    # Configure the Gemini API client
    genai.configure(api_key=api_key)

    # Create a Gemini model instance
    model = genai.GenerativeModel("gemini-1.5-flash")

    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        print(f"Error calling Gemini API: {e}")
        return None

@app.route('/')
def serve_frontend():
    return render_template('index.html')

@app.route('/predict', methods=['POST'])
def predict_suicide_risk():
    try:
        # Validate input
        input_text = request.json.get('text', '').strip()
        if not input_text:
            return jsonify({
                "error": "Invalid input. Please provide a non-empty text for prediction."
            }), 400

        # Preprocess text
        inputs = TOKENIZER(input_text, return_tensors="tf", padding=True, truncation=True, max_length=512)

        # BERT model prediction
        logits = MODEL(inputs["input_ids"], attention_mask=inputs["attention_mask"]).logits
        probabilities = tf.nn.softmax(logits, axis=1).numpy()
        bert_risk_score = float(probabilities[0][1])  # Probability of positive class

        # Gemini API call
        gemini_response = get_gemini_response(f"Analyze the following text for potential suicide ideation: '{input_text}'. Reply with only a float value, with a risk score between 0 and 1") 
        try:
            gemini_risk_score = float(gemini_response) 
        except ValueError:
            print(f"Error parsing Gemini response: {gemini_response}")
            gemini_risk_score = 0.0

        # Weighted average with higher priority to Gemini
        weight_gemini = 0.8  # Adjust this weight as needed
        weight_bert = 0.2 
        combined_risk_score = (gemini_risk_score * weight_gemini) + (bert_risk_score * weight_bert)

        # Geolocation lookup
        ip_address = request.headers.get('X-Forwarded-For', '').split(',')[0].strip() or request.remote_addr
        location_info = get_geolocation(ip_address)

        # Fetch support centers if high risk
        support_centers = []
        if combined_risk_score > 0.7 and location_info:
            support_centers = fetch_local_support_centers(location_info.get('latitude'), location_info.get('longitude'))

        response = {
            "risk_score": combined_risk_score,
            "is_high_risk": combined_risk_score > 0.5,
            "bert_risk_score": bert_risk_score,
            "gemini_risk_score": gemini_risk_score,
        }
        return jsonify(response), 200

    except Exception as e:
        return jsonify({
            "error": str(e),
            "message": "An error occurred during prediction"
        }), 500
    00

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({"status": "healthy"}), 200

if __name__ == '__main__':
    app.run(debug=True)